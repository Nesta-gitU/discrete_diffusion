{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97d5c0b7-0286-4010-80cf-602f88b930bb",
   "metadata": {},
   "source": [
    "# Reweighted loss functions for the neural flow diffusion model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88194bd2-3260-478f-9ebf-43524f23b8c3",
   "metadata": {},
   "source": [
    "## Variational diffusion models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b480d1c-c11b-44c4-9862-5c15b12cd820",
   "metadata": {},
   "source": [
    "### Definition of the forward process\n",
    "\n",
    "Let's define the forward process\n",
    "\n",
    "\\begin{align}\n",
    "    z = \\alpha x + \\sigma \\varepsilon,\n",
    "    \\quad \\text{where} \\quad\n",
    "    \\alpha^2 + \\sigma^2 = 1\n",
    "\\end{align}\n",
    "\n",
    "Then we have the following connections:\n",
    "\n",
    "\\begin{align}\n",
    "    x = \\frac{z - \\sigma \\varepsilon}{\\alpha}\n",
    "    \\quad \\text{and} \\quad\n",
    "    \\varepsilon = \\frac{z - \\alpha x}{\\sigma}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0acfc7-2fcd-4f5c-8ce6-acb65d6fc807",
   "metadata": {},
   "source": [
    "### Signal-To-Noise Ratio (SNR)\n",
    "\n",
    "Introduce the Signal-To-Noise Ratio (SNR)\n",
    "\n",
    "\\begin{align}\n",
    "    SNR = \\frac{\\alpha^2}{\\sigma^2}\n",
    "\\end{align}\n",
    "\n",
    "Reparametrization through the gamma function\n",
    "\n",
    "\\begin{align}\n",
    "    SNR = e^{-\\gamma}\n",
    "\\end{align}\n",
    "\n",
    "Then we can rewrite the $\\alpha$ and $\\sigma$ coefficients in terms of the gamma function\n",
    "\n",
    "\\begin{align}\n",
    "    SNR = \\frac{\\alpha^2}{1 - \\alpha^2} = e^{-\\gamma}\n",
    "    \\quad \\Rightarrow \\quad\n",
    "    \\alpha^2 &= \\frac{e^{-\\gamma}}{1 + e^{-\\gamma}} = \\frac{1}{1 + e^{\\gamma}} = \\sigma(-\\gamma) \\\\\n",
    "    \\sigma^2 &= 1 - \\alpha^2 = \\frac{1}{1 + e^{-\\gamma}} = \\sigma(\\gamma)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e88cbe-684b-44a7-81f8-35d5ac45021f",
   "metadata": {},
   "source": [
    "### Conditional ODE and SDEs\n",
    "\n",
    "The conditional ODE is\n",
    "\n",
    "\\begin{align}\n",
    "    f = \\dot{\\alpha} x + \\dot{\\sigma} \\varepsilon = \\dot{\\alpha} x + \\frac{\\dot{\\sigma}}{\\sigma} (z - \\alpha x)\n",
    "\\end{align}\n",
    "\n",
    "The conditional score function is\n",
    "\n",
    "\\begin{align}\n",
    "    s = - \\frac{\\varepsilon}{\\sigma} = \\frac{\\alpha x - z}{\\sigma^2}\n",
    "\\end{align}\n",
    "\n",
    "Combining the drift of the ODE $f$ and the score function $s$ with the volatility $g$ we can write down the conditional forward SDE\n",
    "\n",
    "\\begin{align}\n",
    "    d z = f^F d t + g d w, \\quad \\text{where} \\quad f^F = f + \\frac{g^2}{2} s\n",
    "\\end{align}\n",
    "\n",
    "Similarly, we can write down the conditional backward SDE\n",
    "\n",
    "\\begin{align}\n",
    "    d z = f^B d t + g d \\bar{w}, \\quad \\text{where} \\quad f^B = f - \\frac{g^2}{2} s\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b03f8a-f1d1-4624-95c5-22b4d1b84a1b",
   "metadata": {},
   "source": [
    "### Derivation of the volatility\n",
    "\n",
    "In general, the volatility $g$ can be an arbitrary function of time $t$. However, there is one useful consideration that can help us parameterise in a more efficient way.\n",
    "\n",
    "\n",
    "In diffusion models, we aim to match the distribution of trajectories of the forward and reversed processes. The reverse process is Markovian by design. Therefore, to be able to match the distributions of trajectories, the forward process should also be Markovian. TO guaranry this, we can find such a volatility $g$ that makes the forward process independent on $x$.\n",
    "\n",
    "I don't know how to derive $g$ analytically in general case, but we can do it in case of the VDM.\n",
    "\n",
    "\\begin{align}\n",
    "    f^F\n",
    "    &= f + \\frac{g^2}{2} s \\\\\n",
    "    &= \\dot{\\alpha} x + \\frac{\\dot{\\sigma}}{\\sigma} (z - \\alpha x) + \\frac{g^2}{2} \\frac{\\alpha x - z}{\\sigma^2} \\\\\n",
    "    &= \\underbrace{ \\left( \\dot{\\alpha} - \\frac{\\dot{\\sigma}}{\\sigma} \\alpha + \\frac{g^2}{2} \\frac{\\alpha}{\\sigma^2} \\right) }_{=0} x + \\left( \\frac{\\dot{\\sigma}}{\\sigma} - \\frac{g^2}{2} \\frac{1}{\\sigma^2} \\right) z \\\\\n",
    "\\end{align}\n",
    "\n",
    "That gives us the expression for the volatility\n",
    "\n",
    "\\begin{align}\n",
    "    g^2\n",
    "    &= 2 \\frac{\\sigma^2}{\\alpha} \\left( \\frac{\\dot{\\sigma}}{\\sigma} \\alpha - \\dot{\\alpha} \\right) \\\\\n",
    "    &= 2 \\sigma \\dot{\\sigma} - 2 \\sigma^2 \\frac{\\dot{\\alpha}}{\\alpha} \\\\\n",
    "    &= (\\sigma^2)' - 2 (\\log \\alpha)' \\sigma^2\n",
    "\\end{align}\n",
    "\n",
    "We can also rewrite the volatility in terms of the gamma function\n",
    "\n",
    "\\begin{align}\n",
    "    g^2\n",
    "    &= (\\sigma^2)' - 2 (\\log \\alpha)' \\sigma^2 \\\\\n",
    "    &= (\\sigma^2)' - \\frac{2 \\alpha \\dot{\\alpha}}{\\alpha^2} \\sigma^2 \\\\\n",
    "    &= (\\sigma(\\gamma))' - \\frac{(\\sigma(-\\gamma))'}{\\sigma(-\\gamma)} \\sigma(\\gamma) \\\\\n",
    "    &= \\sigma(\\gamma) \\left( 1 - \\sigma(\\gamma) \\right) \\dot{\\gamma} + \\frac{\\sigma(-\\gamma) \\left( 1 - \\sigma(-\\gamma) \\right) \\dot{\\gamma}}{\\sigma(-\\gamma)} \\sigma(\\gamma) \\\\\n",
    "    &= \\sigma(\\gamma) \\dot{\\gamma} \\left( 1 - \\sigma(\\gamma) + \\underbrace{1 - \\sigma(-\\gamma)}_{=\\sigma(\\gamma)} \\right) \\\\\n",
    "    &= \\sigma(\\gamma) \\dot{\\gamma}\n",
    "\\end{align}\n",
    "\n",
    "To keep the volatility function general, but preserve the connection with the gamma function, we derived, we can reperametrize the volatility function as follows\n",
    "\n",
    "\\begin{align}\n",
    "    g^2 = \\sigma(\\gamma) \\dot{\\gamma} \\eta\n",
    "\\end{align}\n",
    "\n",
    "where $\\eta$ is an arbitrary non-negative function of time $t$. If we set $\\eta = 1$, we will recover the Markovian volatility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03c5b85-669b-4ae0-9b3d-8c3d32141352",
   "metadata": {},
   "source": [
    "### Reverse process\n",
    "\n",
    "We define the reverse process through prediction $\\hat{x}(z,t)$ that we substitute into the conditional backward SDE:\n",
    "\n",
    "\\begin{align}\n",
    "    d z = \\hat{f}^B d t + g d \\bar{w}, \\quad \\text{where} \\quad \\hat{f}^B(z, t) = f^B(z, t, \\hat{x}(z,t))\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a2500a9755c8e5",
   "metadata": {},
   "source": [
    "### Derivation of the ELBO\n",
    "\n",
    "We know that the ELBO of diffusion models is\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathcal{L} = \\lambda_{f^B} \\left\\| f^B - \\hat{f}^B \\right\\|_2^2, \\quad \\text{where} \\quad \\lambda_{f^B} = \\frac{1}{2 g^2}\n",
    "\\end{align}\n",
    "\n",
    "For VDM, we can rewrite the $f^B$ as:\n",
    "\\begin{align}\n",
    "    f^B\n",
    "    &= f - \\frac{g^2}{2} s \\\\\n",
    "    &= \\dot{\\alpha} x + \\frac{\\dot{\\sigma}}{\\sigma} (z - \\alpha x) - \\frac{g^2}{2} \\frac{\\alpha x - z}{\\sigma^2} \\\\\n",
    "    &= \\left( \\dot{\\alpha} - \\frac{\\dot{\\sigma}}{\\sigma} \\alpha - \\frac{g^2}{2} \\frac{\\alpha}{\\sigma^2} \\right) x + \\left( \\frac{\\dot{\\sigma}}{\\sigma} + \\frac{g^2}{2} \\frac{1}{\\sigma^2} \\right) z\n",
    "\\end{align}\n",
    "\n",
    "Since the second term doesn't depend on $x$ and will cancel out in the ELBO, we can rewrite the ELBO as:\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathcal{L} = \\lambda_x \\left\\| x - \\hat{x} \\right\\|_2^2\n",
    "\\end{align}\n",
    "\n",
    "Let's derive the $\\lambda_x$ coefficient\n",
    "\n",
    "\\begin{align}\n",
    "    \\lambda_x\n",
    "    &= \\frac{1}{2 g^2} \\left( \\dot{\\alpha} - \\frac{\\dot{\\sigma}}{\\sigma} \\alpha - \\frac{g^2}{2} \\frac{\\alpha}{\\sigma^2} \\right)^2 \\\\\n",
    "    &= \\frac{1}{2 g^2} \\left( \\frac{\\alpha}{2} \\frac{2 \\alpha \\dot{\\alpha}}{\\alpha^2} - \\frac{\\alpha}{2} \\frac{2 \\sigma \\dot{\\sigma}}{\\sigma^2} - \\frac{\\alpha}{2} \\frac{g^2}{\\sigma^2} \\right)^2 \\\\\n",
    "    &= \\frac{1}{2 g^2} \\frac{\\alpha^2}{2^2} \\left( \\frac{(\\alpha^2)'}{\\alpha^2} - \\frac{(\\sigma^2)'}{\\sigma^2} - \\frac{g^2}{\\sigma^2} \\right)^2 \\\\\n",
    "    &= \\frac{1}{2} \\frac{\\alpha^2}{\\sigma^2} \\frac{1}{2^2 \\dot{\\gamma} \\eta} \\left( \\frac{(\\alpha^2)'}{\\alpha^2} - \\frac{(\\sigma^2)'}{\\sigma^2} - \\frac{\\sigma^2 \\dot{\\gamma} \\eta}{\\sigma^2} \\right)^2 \\\\\n",
    "    &= \\frac{1}{2} e^{-\\gamma} \\frac{1}{2^2 \\dot{\\gamma} \\eta} \\left( \\frac{\\sigma(-\\gamma) \\left( 1 - \\sigma(-\\gamma) \\right) (-1) \\dot{\\gamma}}{\\sigma(-\\gamma)} - \\frac{\\sigma(\\gamma) \\left( 1 - \\sigma(\\gamma) \\right) \\dot{\\gamma}}{\\sigma(\\gamma)} - \\dot{\\gamma} \\eta \\right)^2 \\\\\n",
    "    &= \\frac{1}{2} e^{-\\gamma} \\frac{1}{2^2 \\dot{\\gamma} \\eta} \\left( \\big[ - \\underbrace{\\left( 1 - \\sigma(-\\gamma) \\right)}_{=\\sigma(\\gamma)} -  1 + \\sigma(\\gamma) \\big] \\dot{\\gamma} - \\dot{\\gamma} \\eta \\right)^2 \\\\\n",
    "    &= \\frac{1}{2} e^{-\\gamma} \\frac{1}{2^2 \\dot{\\gamma} \\eta} \\left( - \\dot{\\gamma} - \\dot{\\gamma} \\eta \\right)^2 \\\\\n",
    "    &= \\frac{1}{2} e^{-\\gamma} \\frac{ \\dot{\\gamma}^2 \\left( 1 + \\eta \\right)^2 }{2^2 \\dot{\\gamma} \\eta} \\\\\n",
    "    &= \\frac{1}{2} e^{-\\gamma} \\dot{\\gamma} \\frac{ \\left( 1 + \\eta \\right)^2 }{2^2 \\eta}\n",
    "\\end{align}\n",
    "\n",
    "Since nothing except the last coefficient depends on function $\\eta$, we can see, we can easily find the optimal $\\eta$. It is $\\eta = 1$. Therefore, the optimal volatility function is a Markovian volatility.\n",
    "\n",
    "We can also find a nice connection with the SNR function, when $\\eta = 1$\n",
    "\n",
    "\\begin{align}\n",
    "    SNR' = (e^{-\\gamma})' = -e^{-\\gamma} \\dot{\\gamma}, \\quad \\lambda_x = \\frac{1}{2} e^{-\\gamma} \\dot{\\gamma} = - \\frac{1}{2} SNR'\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64913d91c9d4bcac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Alternative formulations of the ELBO\n",
    "\n",
    "Similarly, to formulation of the ELBO in terms of the prediction $\\hat{f}^B$ or $\\hat{x}$, we can rewrite the ELBO in terms of prediction of $\\hat{\\varepsilon}$\n",
    "\n",
    "\\begin{align}\n",
    "    x = \\frac{z - \\sigma \\varepsilon}{\\alpha}\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathcal{L} = \\lambda_\\varepsilon \\left\\| \\varepsilon - \\hat{\\varepsilon} \\right\\|_2^2\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "    \\lambda_\\varepsilon\n",
    "    &= \\frac{1}{2} e^{-\\gamma} \\dot{\\gamma} \\frac{ \\left( 1 + \\eta \\right)^2 }{2^2 \\eta} \\frac{\\sigma^2}{\\alpha^2} \\\\\n",
    "    &= \\frac{1}{2} e^{-\\gamma} \\dot{\\gamma} \\frac{ \\left( 1 + \\eta \\right)^2 }{2^2 \\eta} e^{\\gamma} \\\\\n",
    "    &= \\frac{1}{2} \\dot{\\gamma} \\frac{ \\left( 1 + \\eta \\right)^2 }{2^2 \\eta}\n",
    "\\end{align}\n",
    "\n",
    "When $\\eta = 1$, we have\n",
    "\n",
    "\\begin{align}\n",
    "    \\log-SNR' = -\\dot{\\gamma}, \\quad \\lambda_\\varepsilon = \\frac{1}{2} \\dot{\\gamma} = - \\frac{1}{2} \\log-SNR'\n",
    "\\end{align}\n",
    "\n",
    "We can also rewrite the ELBO in terms of the prediction of $\\hat{v}$ function (see Appendix D in [this paper](https://arxiv.org/abs/2202.00512))\n",
    "\n",
    "\\begin{align}\n",
    "    x = \\alpha z - \\sigma v\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathcal{L} = \\lambda_v \\left\\| v - \\hat{v} \\right\\|_2^2\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "    \\lambda_v\n",
    "    &= \\frac{1}{2} e^{-\\gamma} \\dot{\\gamma} \\frac{ \\left( 1 + \\eta \\right)^2 }{2^2 \\eta} \\sigma^2 \\\\\n",
    "    &= \\frac{1}{2} \\frac{e^{-\\gamma}}{1 + e^{-\\gamma}} \\dot{\\gamma} \\frac{ \\left( 1 + \\eta \\right)^2 }{2^2 \\eta} \\\\\n",
    "    &= \\frac{1}{2} \\sigma(-\\gamma) \\dot{\\gamma} \\frac{ \\left( 1 + \\eta \\right)^2 }{2^2 \\eta} \\\\\n",
    "    &= \\frac{1}{2} \\alpha^2 \\dot{\\gamma} \\frac{ \\left( 1 + \\eta \\right)^2 }{2^2 \\eta}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0907bbc40101c27",
   "metadata": {},
   "source": [
    "### Reweighted ELBO formulations\n",
    "\n",
    "As we know from a lot of papers, diffusion models often have better performance when trained not with the ELBO objective, but with reweighted ELBO functions like:\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathcal{L}_x = \\left\\| x - \\hat{x} \\right\\|_2^2 = \\frac{1}{\\lambda_x} \\mathcal{L} \\quad \\text{or} \\quad \\mathcal{L}_\\varepsilon = \\left\\| \\varepsilon - \\hat{\\varepsilon} \\right\\|_2^2 = \\frac{1}{\\lambda_\\varepsilon} \\mathcal{L}\n",
    "\\end{align}\n",
    "\n",
    "But what should we do if the model predicts $\\hat{x}$ and we want to train a model with $\\mathcal{L}_\\varepsilon$? We can simply take the $\\mathcal{L}_x$ or $\\mathcal{L}$ and reweight it!\n",
    "\\begin{align}\n",
    "    \\mathcal{L}_\\varepsilon = \\frac{\\lambda_x}{\\lambda_\\varepsilon} \\mathcal{L}_x = \\frac{1}{\\lambda_\\varepsilon} \\mathcal{L}\n",
    "\\end{align}\n",
    "\n",
    "Importantly, the choice of the reweighting coefficient doesn't depend on the parameterization of the model. We can parameterize the model throgh prediction $\\hat{x}$, $\\hat{\\varepsilon}$, or $\\hat{v}$ with same objective function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d785e85329dad83",
   "metadata": {},
   "source": [
    "## Rewaighted ELBO for NFDM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb40564a218c136",
   "metadata": {},
   "source": [
    "### General case\n",
    "\n",
    "In the general case, when the forward process defined as\n",
    "\n",
    "\\begin{align}\n",
    "    z = F(\\varepsilon, t, x),\n",
    "\\end{align}\n",
    "\n",
    "there is not much we can do. We can rewaight the ELBO with the $\\frac{1}{2 g^2}$ coefficient, which is a part of the ELBO, but I'm not sure if it will help. We can also try to rewaight the ELBO with the different $\\lambda$ coefficients from VDM. However, since $F$ doesn't have any connections with the SNR, I don't now what such a reweighting can give us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d75c770527251f",
   "metadata": {},
   "source": [
    "### Less general case\n",
    "\n",
    "We can consider the case with a less general forward process\n",
    "\n",
    "\\begin{align}\n",
    "    z = \\alpha F(x, t) + \\sigma G(x, t) \\varepsilon\n",
    "\\end{align}\n",
    "\n",
    "This is a Gaussian forward process and it does have a connection with the SNR function. Therefore, we can reweight the ELBO with the $\\lambda$ coefficients from VDM. If $F=x$ and $G=1$, we will recover exactly the VDM case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6329cee14dc0fd92",
   "metadata": {},
   "source": [
    "### NDM\n",
    "\n",
    "We can simplify the forward process a bit more and consider the NDM case\n",
    "\n",
    "\\begin{align}\n",
    "    z = \\alpha F(x, t) + \\sigma \\varepsilon\n",
    "\\end{align}\n",
    "\n",
    "For this case, the same logic applies. We can take the true ELBO and reweight it with the $\\lambda$ coefficients from VDM. However, in this case we can even slightly simplify the calculations. Let's write down the ELBO for the NDM:\n",
    "\n",
    "\\begin{align}\n",
    "    f^B\n",
    "    &= f - \\frac{g^2}{2} s \\\\\n",
    "    &= \\dot{\\alpha} F + \\alpha \\dot{F} + \\frac{\\dot{\\sigma}}{\\sigma} (z - \\alpha F) - \\frac{g^2}{2} \\frac{\\alpha F - z}{\\sigma^2} \\\\\n",
    "    &= \\left( \\dot{\\alpha} - \\frac{\\dot{\\sigma}}{\\sigma} \\alpha - \\frac{g^2}{2} \\frac{\\alpha}{\\sigma^2} \\right) F + \\alpha \\dot{F} + \\left( \\frac{\\dot{\\sigma}}{\\sigma} + \\frac{g^2}{2} \\frac{1}{\\sigma^2} \\right) z\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathcal{L} \n",
    "    &= \\frac{1}{2 g^2} \\left\\| f^B - \\hat{f}^B \\right\\|_2^2 \\\\\n",
    "    &= \\frac{1}{2 g^2} \\left\\| \\left( \\dot{\\alpha} - \\frac{\\dot{\\sigma}}{\\sigma} \\alpha - \\frac{g^2}{2} \\frac{\\alpha}{\\sigma^2} \\right) \\left( F - \\hat{F} \\right) + \\alpha \\left( \\dot{F} - \\dot{\\hat{F}} \\right) \\right\\|_2^2 \\\\\n",
    "    &= \\frac{1}{2} \\left\\| \\frac{1}{g} \\left( \\dot{\\alpha} - \\frac{\\dot{\\sigma}}{\\sigma} \\alpha - \\frac{g^2}{2} \\frac{\\alpha}{\\sigma^2} \\right) \\left( F - \\hat{F} \\right) + \\frac{\\alpha}{g} \\left( \\dot{F} - \\dot{\\hat{F}} \\right) \\right\\|_2^2 \\\\\n",
    "    &= \\frac{1}{2} \\left\\| \\sqrt{2 \\lambda_x} \\left( F - \\hat{F} \\right) + \\frac{\\alpha}{g} \\left( \\dot{F} - \\dot{\\hat{F}} \\right) \\right\\|_2^2 \\\\\n",
    "    &= \\frac{1}{2} \\left\\| \\sqrt{2 \\lambda_x} \\left( F - \\hat{F} \\right) + \\frac{\\alpha}{\\sigma} \\frac{\\sqrt{\\dot{\\gamma}}}{\\dot{\\gamma}} \\frac{\\sqrt{\\eta}}{\\eta} \\left( \\dot{F} - \\dot{\\hat{F}} \\right) \\right\\|_2^2 \\\\\n",
    "    &= \\frac{1}{2} \\left\\| e^{-\\frac{\\gamma}{2}} \\sqrt{\\dot{\\gamma}} \\frac{ 1 + \\eta }{2} \\frac{\\sqrt{\\eta}}{\\eta} \\left( F - \\hat{F} \\right) + e^{-\\frac{\\gamma}{2}} \\frac{\\sqrt{\\dot{\\gamma}}}{\\dot{\\gamma}} \\frac{\\sqrt{\\eta}}{\\eta} \\left( \\dot{F} - \\dot{\\hat{F}} \\right) \\right\\|_2^2 \\\\\n",
    "    &= \\frac{1}{2} e^{-\\gamma} \\dot{\\gamma} \\frac{1}{\\eta} \\left\\| \\frac{ 1 + \\eta }{2} \\left( F - \\hat{F} \\right) + \\frac{1}{\\dot{\\gamma}} \\left( \\dot{F} - \\dot{\\hat{F}} \\right) \\right\\|_2^2 \\\\\n",
    "    &= \\lambda_F \\left\\| \\frac{ 1 + \\eta }{2} \\left( F - \\hat{F} \\right) + \\frac{1}{\\dot{\\gamma}} \\left( \\dot{F} - \\dot{\\hat{F}} \\right) \\right\\|_2^2, \\quad \\text{where} \\quad \\lambda_F = \\frac{1}{2} e^{-\\gamma} \\dot{\\gamma} \\frac{1}{\\eta}\n",
    "\\end{align}\n",
    "\n",
    "Importantly, $\\eta = 1$ doesn't necessarily minimises the ELBO in this case.\n",
    "\n",
    "Therefore, if we want to train the NDM with $\\mathcal{L}_x$ objective, we can do it as follows\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathcal{L}_x\n",
    "    &= \\frac{1}{\\lambda_x} \\mathcal{L} \\\\\n",
    "    &= \\frac{\\lambda_F}{\\lambda_x} \\left\\| \\frac{ 1 + \\eta }{2} \\left( F - \\hat{F} \\right) + \\frac{1}{\\dot{\\gamma}} \\left( \\dot{F} - \\dot{\\hat{F}} \\right) \\right\\|_2^2 \\\\\n",
    "    &= \\frac{ \\frac{1}{2} e^{-\\gamma} \\dot{\\gamma} \\frac{1}{\\eta} }{ \\frac{1}{2} e^{-\\gamma} \\dot{\\gamma} \\frac{ \\left( 1 + \\eta \\right)^2 }{2^2 \\eta} } \\left\\| \\frac{ 1 + \\eta }{2} \\left( F - \\hat{F} \\right) + \\frac{1}{\\dot{\\gamma}} \\left( \\dot{F} - \\dot{\\hat{F}} \\right) \\right\\|_2^2 \\\\\n",
    "    &= \\frac{ 2^2 }{ \\left( 1 + \\eta \\right)^2 } \\left\\| \\frac{ 1 + \\eta }{2} \\left( F - \\hat{F} \\right) + \\frac{1}{\\dot{\\gamma}} \\left( \\dot{F} - \\dot{\\hat{F}} \\right) \\right\\|_2^2\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe7629fb7b031f6",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6dd6cac4ee22d7",
   "metadata": {},
   "source": [
    "### Imports and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:41:28.977970Z",
     "start_time": "2025-03-09T16:41:27.883631Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Callable, Optional\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import functional as F\n",
    "import torch.distributions as D\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "ec7382d8d6dbacb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:41:28.983457Z",
     "start_time": "2025-03-09T16:41:28.980978Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 64),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(64, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, t: Tensor) -> Tensor:\n",
    "        return self.net(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "c4f0b3bbf8c13a70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:41:29.020566Z",
     "start_time": "2025-03-09T16:41:29.017755Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def solve_sde(\n",
    "        sde: Callable[[Tensor, Tensor], tuple[Tensor, Tensor]],\n",
    "        z: Tensor,\n",
    "        ts: float,\n",
    "        tf: float,\n",
    "        n_steps: int,\n",
    "        show_pbar: bool=False\n",
    "):\n",
    "    bs = z.shape[0]\n",
    "\n",
    "    t_steps = torch.linspace(ts, tf, n_steps + 1)\n",
    "    dt = (tf - ts) / n_steps\n",
    "    dt_2 = abs(dt) ** 0.5\n",
    "\n",
    "    path = [z]\n",
    "    pbar = tqdm if show_pbar else (lambda a: a)\n",
    "    for t in pbar(t_steps[:-1]):\n",
    "        t = t.expand(bs, 1)\n",
    "\n",
    "        f, g = sde(z, t)\n",
    "\n",
    "        w = torch.randn_like(z)\n",
    "        z = z + f * dt + g * w * dt_2\n",
    "\n",
    "        path.append(z)\n",
    "\n",
    "    return z, (t_steps, torch.stack(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "25f926f2265269f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:41:29.033860Z",
     "start_time": "2025-03-09T16:41:29.025046Z"
    }
   },
   "outputs": [],
   "source": [
    "class TimeSampler(nn.Module, ABC):\n",
    "    def __init__(self, salt_fraction: Optional[int] = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self._salt_fraction = salt_fraction\n",
    "\n",
    "    @abstractmethod\n",
    "    def prob(self, t: Tensor) -> Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def sample(self, bs: int) -> Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def loss(self, loss: Tensor, t: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        In terms of minimization of the variance, this loss is not quite correct. Firstly, in lit module,\n",
    "        we detach t and loss. Theoretically we should differentiate end-to-end through loss to obtain\n",
    "        the true gradient w.r.t. parameters of the proposal distribution. However, to do this, we must\n",
    "        differentiate through the training step second time just to optimize the proposal distribution,\n",
    "        which is too expensive. Therefore, we detach t and loss and work with biased gradient. Secondly,\n",
    "        we should take into account the salting, which we don't.\n",
    "        \"\"\"\n",
    "\n",
    "        p = self.prob(t)\n",
    "\n",
    "        l2 = loss ** 2\n",
    "        p2 = p ** 2\n",
    "\n",
    "        return l2 / p2\n",
    "\n",
    "    def forward(self, bs: int) -> tuple[Tensor, Tensor]:\n",
    "        t = self.sample(bs)\n",
    "\n",
    "        dtype = t.dtype\n",
    "        device = t.device\n",
    "\n",
    "        if self._salt_fraction is not None:\n",
    "            assert bs % self._salt_fraction == 0\n",
    "\n",
    "            bs2 = bs // self._salt_fraction\n",
    "            bs1 = bs - bs2\n",
    "\n",
    "            un = D.Uniform(\n",
    "                torch.tensor([0.], dtype=dtype, device=device),\n",
    "                torch.tensor([1.], dtype=dtype, device=device)\n",
    "            )\n",
    "            u = un.sample(torch.Size((bs2,)))\n",
    "\n",
    "            t = torch.cat([t[:bs1], u], dim=0)\n",
    "\n",
    "            p = self.prob(t)\n",
    "\n",
    "            k = 1 / self._salt_fraction\n",
    "            p = p * (1 - k) + k\n",
    "        else:\n",
    "            p = self.prob(t)\n",
    "\n",
    "        return t, p\n",
    "\n",
    "\n",
    "class UniformSampler(TimeSampler):\n",
    "    def __init__(self, salt_fraction: Optional[int] = None):\n",
    "        super().__init__(salt_fraction)\n",
    "\n",
    "        self.register_buffer(\"_l\", torch.tensor(0.))\n",
    "        self.register_buffer(\"_r\", torch.tensor(1.))\n",
    "\n",
    "    @property\n",
    "    def _u(self) -> D.Uniform:\n",
    "        return D.Uniform(self._l, self._r)\n",
    "\n",
    "    def prob(self, t: Tensor) -> Tensor:\n",
    "        return self._u.log_prob(t).squeeze(dim=1).exp()\n",
    "\n",
    "    def sample(self, bs: int) -> Tensor:\n",
    "        return self._u.sample(torch.Size((bs, 1)))\n",
    "\n",
    "\n",
    "class BucketSampler(TimeSampler):\n",
    "    def __init__(self, n: int = 100, salt_fraction: Optional[int] = None):\n",
    "        super().__init__(salt_fraction)\n",
    "\n",
    "        self._logits = nn.Parameter(torch.ones(n))\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def _bucket_prob(self) -> Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def _bucket_width(self) -> Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @property\n",
    "    def _bucket_height(self) -> Tensor:\n",
    "        return self._bucket_prob / self._bucket_width\n",
    "\n",
    "    @property\n",
    "    def _bucket_bounds(self) -> tuple[Tensor, Tensor]:\n",
    "        w = self._bucket_width\n",
    "\n",
    "        dtype = w.dtype\n",
    "        device = w.device\n",
    "\n",
    "        b_r = torch.cumsum(w, dim=0)\n",
    "        b_l = torch.cat([torch.zeros(1, dtype=dtype, device=device), b_r[:-1]])\n",
    "\n",
    "        return b_l, b_r\n",
    "\n",
    "    def prob(self, t: Tensor) -> Tensor:\n",
    "        t = t.flatten()\n",
    "\n",
    "        t, ids_t = torch.sort(t)\n",
    "        inv_ids_t = torch.argsort(ids_t)\n",
    "\n",
    "        b_l, _ = self._bucket_bounds\n",
    "\n",
    "        ids_p = torch.searchsorted(b_l, t, right=True) - 1\n",
    "\n",
    "        p = self._bucket_height\n",
    "        p = torch.index_select(p, 0, ids_p)\n",
    "        p = torch.index_select(p, 0, inv_ids_t)\n",
    "\n",
    "        return p\n",
    "\n",
    "    def sample(self, bs: int) -> Tensor:\n",
    "        b_p = self._bucket_prob\n",
    "        b_l, b_r = self._bucket_bounds\n",
    "\n",
    "        dtype = b_p.dtype\n",
    "        device = b_p.device\n",
    "\n",
    "        cat = D.Categorical(b_p)\n",
    "        ids = cat.sample(torch.Size((bs,)))\n",
    "\n",
    "        un = D.Uniform(\n",
    "            torch.tensor(0., dtype=dtype, device=device),\n",
    "            torch.tensor(1., dtype=dtype, device=device)\n",
    "        )\n",
    "        u = un.sample(torch.Size((bs,)))\n",
    "\n",
    "        t = torch.index_select(b_l, 0, ids) + torch.index_select(b_r - b_l, 0, ids) * u\n",
    "        t = t[:, None]\n",
    "\n",
    "        return t\n",
    "\n",
    "\n",
    "class UniformBucketSampler(BucketSampler):\n",
    "    @property\n",
    "    def _bucket_prob(self) -> Tensor:\n",
    "        logits = self._logits\n",
    "        logits = torch.clamp(logits, min=-10, max=10)\n",
    "\n",
    "        return torch.softmax(logits, dim=0)\n",
    "\n",
    "    @property\n",
    "    def _bucket_width(self) -> Tensor:\n",
    "        logits = self._logits\n",
    "        dtype = logits.dtype\n",
    "        device = logits.device\n",
    "        n = logits.shape[0]\n",
    "        return torch.ones(n, dtype=dtype, device=device) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "f5aff0f729531210",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:41:29.039891Z",
     "start_time": "2025-03-09T16:41:29.038184Z"
    }
   },
   "outputs": [],
   "source": [
    "def viz_2d_data(data: Tensor):\n",
    "    plt.scatter(data[:, 0], data[:, 1], s=1)\n",
    "    plt.axis(\"scaled\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "405b96b0772b1dd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:41:29.046732Z",
     "start_time": "2025-03-09T16:41:29.044026Z"
    }
   },
   "outputs": [],
   "source": [
    "def viz_2d_path(t_steps: Tensor, path: Tensor, n_lines: int=-1, color: str | None=None):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.scatter(15 + path[0, :, 0], path[0, :, 1], s=1)\n",
    "    plt.scatter(path[-1, :, 0], path[-1, :, 1], s=1)\n",
    "    plt.plot(15 * t_steps[:, None] + path[:, :n_lines, 0],\n",
    "             path[:, :n_lines, 1],\n",
    "             color=color, alpha=0.5)\n",
    "    plt.axis(\"scaled\")\n",
    "    plt.tick_params(left=False, labelleft=False,\n",
    "                    bottom=False, labelbottom=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "d217b66a74d47a1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:41:29.053990Z",
     "start_time": "2025-03-09T16:41:29.051205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3185,  2.6203],\n",
      "        [ 3.1038,  0.7389],\n",
      "        [-2.8279,  0.2875],\n",
      "        [-0.0305,  3.1308],\n",
      "        [-2.4964,  2.2137],\n",
      "        [ 2.8037, -0.6512],\n",
      "        [ 2.0267, -1.3573],\n",
      "        [-0.4709,  2.3389],\n",
      "        [ 0.7339,  2.2544],\n",
      "        [-2.1758,  2.1007]])\n"
     ]
    }
   ],
   "source": [
    "def gen_data(n: int):\n",
    "    scale = 4.\n",
    "    centers = torch.tensor([\n",
    "        [1, 0],\n",
    "        [-1, 0],\n",
    "        [0, 1],\n",
    "        [0, -1],\n",
    "        [1. / np.sqrt(2), 1. / np.sqrt(2)],\n",
    "        [1. / np.sqrt(2), -1. / np.sqrt(2)],\n",
    "        [-1. / np.sqrt(2), 1. / np.sqrt(2)],\n",
    "        [-1. / np.sqrt(2), -1. / np.sqrt(2)]\n",
    "    ], dtype=torch.float32)\n",
    "    centers = scale * centers\n",
    "\n",
    "    x = torch.randn(n, 2)\n",
    "    x = 0.5 * x\n",
    "\n",
    "    center_ids = torch.randint(0, 8, (n,))\n",
    "    x = x + centers[center_ids]\n",
    "\n",
    "    x = x / 2 ** 0.5\n",
    "\n",
    "    return x\n",
    "\n",
    "# generates data of dimension 2\n",
    "data = gen_data(10)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a62be700e3c11",
   "metadata": {},
   "source": [
    "### Forward process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "701ffe4f521dde96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:41:29.060240Z",
     "start_time": "2025-03-09T16:41:29.058397Z"
    }
   },
   "outputs": [],
   "source": [
    "def jvp(f, x, v):\n",
    "    return torch.autograd.functional.jvp(\n",
    "        f, x, v,\n",
    "        create_graph=torch.is_grad_enabled()\n",
    "    )\n",
    "\n",
    "\n",
    "def t_dir(f, t):\n",
    "    return jvp(f, t, torch.ones_like(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "4af5e7adc5483e1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:41:29.066589Z",
     "start_time": "2025-03-09T16:41:29.064453Z"
    }
   },
   "outputs": [],
   "source": [
    "class AffineTransform(nn.Module, ABC):\n",
    "    @abstractmethod\n",
    "    def get_m_s(self, x: Tensor, t: Tensor) -> tuple[Tensor, Tensor]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, x: Tensor, t: Tensor) -> tuple[tuple[Tensor, Tensor], tuple[Tensor, Tensor]]:\n",
    "        def f(t_in):\n",
    "            return self.get_m_s(x, t_in)\n",
    "\n",
    "        return t_dir(f, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "8ca89ed17a1ab35c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:41:29.074011Z",
     "start_time": "2025-03-09T16:41:29.071185Z"
    }
   },
   "outputs": [],
   "source": [
    "class AffineTransformID(AffineTransform):\n",
    "    @staticmethod\n",
    "    def get_m_s(x, t):\n",
    "        m = x\n",
    "        s = torch.ones_like(x)\n",
    "        return m, s\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(x, t): # this is VDM. \n",
    "        m, s = AffineTransformID.get_m_s(x, t)\n",
    "\n",
    "        dm = torch.zeros_like(x)\n",
    "        ds = torch.zeros_like(x)\n",
    "\n",
    "        return (m, s), (dm, ds)\n",
    "\n",
    "\n",
    "class AffineTransformHalfNeural(AffineTransform):\n",
    "    def __init__(self, d: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = Net(d, d)\n",
    "\n",
    "    def get_m_s(self, x, t):\n",
    "        #x_t = torch.cat([x, t], dim=1)\n",
    "        m = self.net(x)\n",
    "\n",
    "        #m = x + t * m\n",
    "        s = torch.ones_like(x)\n",
    "\n",
    "        return m, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "a9dc94f03b8d5ace",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:41:29.080854Z",
     "start_time": "2025-03-09T16:41:29.078374Z"
    }
   },
   "outputs": [],
   "source": [
    "class Gamma(nn.Module, ABC):\n",
    "    @staticmethod\n",
    "    def alpha_2(g):\n",
    "        return torch.sigmoid(-g)\n",
    "\n",
    "    @staticmethod\n",
    "    def sigma_2(g):\n",
    "        return torch.sigmoid(g)\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_gamma(self, t: Tensor) -> Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, t: Tensor) -> tuple[Tensor, Tensor]:\n",
    "        return t_dir(self.get_gamma, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "2d2407ebefe9fcf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:41:29.087510Z",
     "start_time": "2025-03-09T16:41:29.085433Z"
    }
   },
   "outputs": [],
   "source": [
    "class GammaLinear(Gamma):\n",
    "    @staticmethod\n",
    "    def get_gamma(t):\n",
    "        return -10 + 20 * t\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(t):\n",
    "        g = GammaLinear.get_gamma(t)\n",
    "        dg = torch.ones_like(t) * 20\n",
    "        return g, dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "57b352085eead962",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:41:29.095591Z",
     "start_time": "2025-03-09T16:41:29.091922Z"
    }
   },
   "outputs": [],
   "source": [
    "class PosLinear(nn.Linear):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.sp = nn.Softplus()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        weight = self.sp(self.weight)\n",
    "        bias = self.bias\n",
    "        return F.linear(x, weight, bias)\n",
    "\n",
    "\n",
    "class GammaVDM(Gamma):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = PosLinear(1, 1)\n",
    "        self.fc2 = PosLinear(1, 1024)\n",
    "        self.fc3 = PosLinear(1024, 1)\n",
    "\n",
    "    def get_unnorm_gamma(self, x):\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        y = self.fc2(x)\n",
    "        y = torch.sigmoid(y)\n",
    "        y = self.fc3(y)\n",
    "\n",
    "        return x + y\n",
    "\n",
    "    def get_gamma(self, t):\n",
    "        x_0 = torch.zeros(1, 1)\n",
    "        x_1 = torch.ones(1, 1)\n",
    "        y_0 = torch.ones(1, 1) * (-10)\n",
    "        y_1 = torch.ones(1, 1) * 10 #flag\n",
    "        y_gap = y_1 - y_0\n",
    "\n",
    "        x_adj = torch.cat([x_0, x_1, t], dim=0)\n",
    "        y_adj = self.get_unnorm_gamma(x_adj)\n",
    "        yo_0, yo_1, yo = y_adj[:1], y_adj[1:2], y_adj[2:]\n",
    "\n",
    "        y = y_0 + (y_1 - y_0) * (yo - yo_0) / (yo_1 - yo_0)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "2ec69a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GammaMuLAN(Gamma):\n",
    "    #implement get_gamma and forward methods\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        self.gamma_shape = config.gamma_shape\n",
    "        self.n_features = config.seq_len * config.embedding_dim #what does this reflect? -> n flattend features \n",
    "        self.min_gamma = self.config.gamma_min\n",
    "        self.max_minus_min_gamma = self.config.gamma_max - self.config.gamma_min\n",
    "        self.grad_min_epsilon = 0.001\n",
    "\n",
    "\n",
    "\n",
    "        #self.l1 = nn.Linear(self.n_features, self.n_features)\n",
    "        #if I want the noise injection to not depend on the input, more like vdm, since input dependence will be injected through ndm function transformation, I can just make the input of\n",
    "        #l1 to be 1. which means the input is just the time t. That is not fully equal to MuLAN since there the a, b, d are dependent only on input not on t.\n",
    "        #that also mean I will still need to implement the get_gamma method, but not the forward method, we need tdir still. \n",
    "        self.l1 = nn.Linear(2, self.n_features)\n",
    "        self.l2 = nn.Linear(self.n_features, self.n_features)\n",
    "        self.l3_a = nn.Linear(self.n_features, self.n_features)\n",
    "        self.l3_b = nn.Linear(self.n_features, self.n_features)\n",
    "        self.l3_c = nn.Linear(self.n_features, self.n_features)\n",
    "\n",
    "    def _eval_polynomial(self, a, b, c, t):\n",
    "        # Polynomial evaluation\n",
    "        polynomial = (\n",
    "            (a ** 2) * (t ** 5) / 5.0\n",
    "            + (b ** 2 + 2 * a * c) * (t ** 3) / 3.0\n",
    "            + a * b * (t ** 4) / 2.0\n",
    "            + b * c * (t ** 2)\n",
    "            + (c ** 2 + self.grad_min_epsilon) * t)\n",
    "        \n",
    "        scale = ((a ** 2) / 5.0\n",
    "                 + (b ** 2 + 2 * a * c) / 3.0\n",
    "                 + a * b / 2.0\n",
    "                 + b * c\n",
    "                 + (c ** 2 + self.grad_min_epsilon))\n",
    "\n",
    "        return self.min_gamma + self.max_minus_min_gamma * polynomial / scale\n",
    "    \n",
    "    def _grad_t(self, a, b, c, t):\n",
    "        # derivative = (at^2 + bt + c)^2\n",
    "        polynomial = (\n",
    "        (a ** 2) * (t ** 4)\n",
    "        + (b ** 2 + 2 * a * c) * (t ** 2)\n",
    "        + a * b * (t ** 3) * 2.0\n",
    "        + b * c * t * 2\n",
    "        + (c ** 2 + self.grad_min_epsilon))\n",
    "        \n",
    "        scale = ((a ** 2) / 5.0\n",
    "                + (b ** 2 + 2 * a * c) / 3.0\n",
    "                + a * b / 2.0\n",
    "                + b * c\n",
    "                + (c ** 2 + self.grad_min_epsilon))\n",
    "\n",
    "        return self.max_minus_min_gamma * polynomial / scale\n",
    "\n",
    "    def _compute_coefficients(self, x):\n",
    "        _h = torch.nn.functional.silu(self.l1(x))\n",
    "        _h = torch.nn.functional.silu(self.l2(_h))\n",
    "        a = self.l3_a(_h)\n",
    "        b = self.l3_b(_h)\n",
    "        c = 1e-3 + torch.nn.functional.softplus(self.l3_c(_h))\n",
    "        #print(a,b,c)\n",
    "        return a, b, c\n",
    "    \n",
    "    def get_gamma(self, t, x):\n",
    "        a, b, c = self._compute_coefficients(x)\n",
    "        gamma_flat = self._eval_polynomial(a, b, c, t)\n",
    "        #shape should be bs=t.shape[0], gamma_shape\n",
    "        #how do I append a value to the shape though?\n",
    "        \n",
    "        gamma = gamma_flat.view(-1, *self.gamma_shape)\n",
    "        #print(gamma.shape, \"gamma shape\")\n",
    "        return gamma\n",
    "    \n",
    "    def forward(self, t, x):\n",
    "        a, b, c = self._compute_coefficients(x)\n",
    "        dg = self._grad_t(a, b, c, t)\n",
    "        dg = dg.clamp(min=self.grad_min_epsilon)\n",
    "        return self.get_gamma(t, x), dg\n",
    "\n",
    "    #def forward(self, t):\n",
    "    #    gamma, dgamma = t_dir(self.get_gamma, t)\n",
    "    #    #dgamma = torch.clamp(dgamma, min=self.grad_min_epsilon)\n",
    "    #    return gamma, dgamma\n",
    "    \n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def sigma_2(g):\n",
    "\n",
    "        vector = torch.sigmoid(g)\n",
    "        sigma_2 = torch.diagonal\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "from types import SimpleNamespace\n",
    "\n",
    "mulan_config = SimpleNamespace(\n",
    "                gamma_shape=(1,),\n",
    "                seq_len= 1,\n",
    "                embedding_dim= 1,\n",
    "                gamma_min= -13.3,\n",
    "                gamma_max= 5.0\n",
    "                )\n",
    "\n",
    "gamma_here = GammaMuLAN(mulan_config)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "5bb1ba44e681c730",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:41:29.101414Z",
     "start_time": "2025-03-09T16:41:29.099677Z"
    }
   },
   "outputs": [],
   "source": [
    "class VolatilityEta(nn.Module, ABC):\n",
    "    @abstractmethod\n",
    "    def forward(self, t: Tensor) -> Tensor:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "e2a2701951ed0b8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:41:29.108064Z",
     "start_time": "2025-03-09T16:41:29.105751Z"
    }
   },
   "outputs": [],
   "source": [
    "class VolatilityEtaOne(nn.Module):\n",
    "    def forward(self, t):\n",
    "        return torch.ones_like(t)\n",
    "\n",
    "\n",
    "class VolatilityEtaNeural(nn.Module, ABC):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = Net(1, 1)\n",
    "        self.sp = nn.Softplus()\n",
    "\n",
    "    def forward(self, t):\n",
    "        return self.sp(self.net(t))\n",
    "\n",
    "class VolatilityEtaOneNew(nn.Module):\n",
    "    def forward(self, t):\n",
    "        return torch.ones(t.size(0), 2)\n",
    "#vol = VolatilityEtaOneNew()\n",
    "#print(vol(torch.tensor([1,2,4,5,6,7,54,2,3,4,5,6])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab22518a1370b71",
   "metadata": {},
   "source": [
    "### Reverse process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "eabb9e1ff1eaabef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:41:29.114545Z",
     "start_time": "2025-03-09T16:41:29.112180Z"
    }
   },
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    def __init__(self, d: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = Net(d + 1, d)\n",
    "\n",
    "    def forward(self, z, t):\n",
    "        z_t = torch.cat([z, t], dim=1)\n",
    "        x = self.net(z_t)\n",
    "\n",
    "        x = (1 - t) * z + (t + 0.01) * x\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416548974191c4d",
   "metadata": {},
   "source": [
    "### Neural diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "de00a7a5911f1cba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:41:29.122222Z",
     "start_time": "2025-03-09T16:41:29.118767Z"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralDiffusion(nn.Module):\n",
    "    def __init__(self, transform: AffineTransform, gamma: Gamma, vol_eta: VolatilityEta, pred: Predictor, VAE=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.transform = transform\n",
    "        self.gamma = gamma\n",
    "        self.vol_eta = vol_eta\n",
    "        self.pred = pred\n",
    "        #self.scalar = nn.Parameter(torch.tensor([1.0]))\n",
    "        \n",
    "        self.VAE = VAE\n",
    "        if VAE:\n",
    "            self.model = Net(2, 4)\n",
    "            print(self.model.requires_grad_, \"model requires grad\")\n",
    "        else:\n",
    "            self.model = Net(2, 2)\n",
    "\n",
    "    \n",
    "    def forward(self, x: Tensor, t: Tensor):\n",
    "        #print(\"fakka\")\n",
    "        #print(torch.is_grad_enabled(), \"is grad enabled\")\n",
    "        eps = torch.randn_like(x)\n",
    "\n",
    "        # Check if eps contains NaNs or Infs\n",
    "        if torch.any(torch.isnan(eps)) or torch.any(torch.isinf(eps)):\n",
    "            print(f\"NaN or Inf detected in eps: {eps}\")\n",
    "\n",
    "        if self.VAE:\n",
    "            mean, log_std = self.model(x).chunk(2, dim=1)\n",
    "            std = torch.exp(log_std)\n",
    "            context = mean + std * torch.randn_like(std)\n",
    "        else:\n",
    "            context = self.model(x)\n",
    "\n",
    "        gamma, d_gamma = self.gamma(t, context)\n",
    "\n",
    "        # Check gamma and d_gamma for NaNs and Infs\n",
    "        if torch.any(torch.isnan(gamma)) or torch.any(torch.isinf(gamma)):\n",
    "            print(f\"NaN or Inf detected in gamma: {gamma}\")\n",
    "            print(gamma[torch.isinf(gamma)])\n",
    "            print(gamma[torch.isnan(gamma)])\n",
    "\n",
    "        if torch.any(torch.isnan(d_gamma)) or torch.any(torch.isinf(d_gamma)): # or torch.any(d_gamma < 0.000001):\n",
    "            print(f\"NaN or Inf detected in d_gamma: {d_gamma}\")\n",
    "        \n",
    "        alpha = self.gamma.alpha_2(gamma) ** 0.5\n",
    "        sigma = self.gamma.sigma_2(gamma) ** 0.5\n",
    "\n",
    "        # Check alpha and sigma for NaNs or Infs\n",
    "        if torch.any(torch.isnan(alpha)) or torch.any(torch.isinf(alpha)):\n",
    "            print(f\"NaN or Inf detected in alpha: {alpha}\")\n",
    "        if torch.any(torch.isnan(sigma)) or torch.any(torch.isinf(sigma)):\n",
    "            print(f\"NaN or Inf detected in sigma: {sigma}\")\n",
    "\n",
    "        (m, _), (d_m, _) = self.transform(x, t)\n",
    "\n",
    "        # Check m, d_m for NaNs or Infs\n",
    "        if torch.any(torch.isnan(m)) or torch.any(torch.isinf(m)):\n",
    "            print(f\"NaN or Inf detected in m: {m}\")\n",
    "        if torch.any(torch.isnan(d_m)) or torch.any(torch.isinf(d_m)):\n",
    "            print(f\"NaN or Inf detected in d_m: {d_m}\")\n",
    "\n",
    "        eta = self.vol_eta(t)\n",
    "\n",
    "        # Check eta for NaNs or Infs\n",
    "        if torch.any(torch.isnan(eta)) or torch.any(torch.isinf(eta)):\n",
    "            print(f\"NaN or Inf detected in eta: {eta}\")\n",
    "\n",
    "        z = alpha * m + sigma * eps\n",
    "\n",
    "        # Check z for NaNs or Infs\n",
    "        if torch.any(torch.isnan(z)) or torch.any(torch.isinf(z)):\n",
    "            print(f\"NaN or Inf detected in z: {z}\")\n",
    "\n",
    "        x_ = self.pred(z, t)\n",
    "        #print(x_.requires_grad, \"x_ requires grad\")\n",
    "\n",
    "        # Check x_ for NaNs or Infs\n",
    "        if torch.any(torch.isnan(x_)) or torch.any(torch.isinf(x_)):\n",
    "            print(f\"NaN or Inf detected in x_: {x_}\")\n",
    "\n",
    "        (m_, _), (d_m_, _) = self.transform(x_, t)\n",
    "\n",
    "        # Check m_, d_m_ for NaNs or Infs\n",
    "        if torch.any(torch.isnan(m_)) or torch.any(torch.isinf(m_)):\n",
    "            print(f\"NaN or Inf detected in m_: {m_}\")\n",
    "        if torch.any(torch.isnan(d_m_)) or torch.any(torch.isinf(d_m_)):\n",
    "            print(f\"NaN or Inf detected in d_m_: {d_m_}\")\n",
    "\n",
    "        # ELBO weighting\n",
    "        lmbd = 0.5 * torch.exp(-gamma) * d_gamma / eta\n",
    "        #lmbd = 0.5 * torch.exp(-self.scalar * gamma) * d_gamma / eta\n",
    "        #lmbd = 0.5 * 8 / eta\n",
    "        #print(lmbd)\n",
    "\n",
    "        \n",
    "        #lmbd = 0.5 * d_gamma / eta\n",
    "        #print(\"exp gamma is : \", torch.exp(-gamma))\n",
    "        #print(\"d_gamma is : \", d_gamma)\n",
    "\n",
    "        # Check lmbd for NaNs or Infs\n",
    "        if torch.any(torch.isnan(lmbd)) or torch.any(torch.isinf(lmbd)):\n",
    "            print(f\"NaN or Inf detected in lmbd: {lmbd}\")\n",
    "\n",
    "        # L_x weighting (optional, commented out)\n",
    "        #lmbd = (4 / (1 + eta) ** 2) \n",
    "        #print(\"lmbd is: \", lmbd) #should just be 1, it is\n",
    "        one_over_dgamma = torch.clamp(1 / (d_gamma), max=10000) \n",
    "        if torch.any(one_over_dgamma == 10000):\n",
    "            print(\"clamped\")\n",
    "        \n",
    "        #print(\"one_over_dgamma is: \", one_over_dgamma) #should just be 1, it is\n",
    "\n",
    "        loss = (1 + eta) / 2 * (m - m_) + one_over_dgamma * (d_m - d_m_)\n",
    "\n",
    "        #print(d_gamma[d_gamma < 0.000001], \"dgamma\")\n",
    "        #print(one_over_dgamma[d_gamma < 0.000001])\n",
    "        #print(d_m-d_m_, \"should be zero\")\n",
    "        #print(one_over_dgamma*(d_m - d_m_), \"should be zero\")\n",
    "       \n",
    "        #print(\"unscaled loss is: \", loss)\n",
    "\n",
    "        # Check intermediate loss for NaNs or Infs\n",
    "        if torch.any(torch.isnan(loss)) or torch.any(torch.isinf(loss)):\n",
    "            print(f\"NaN or Inf detected in loss before squaring: {loss}\")\n",
    "\n",
    "        loss = loss ** 2\n",
    "\n",
    "        # Check squared loss for NaNs or Infs\n",
    "        if torch.any(torch.isnan(loss)) or torch.any(torch.isinf(loss)):\n",
    "            print(f\"NaN or Inf detected in squared loss: {loss}\")\n",
    "\n",
    "        # Stabilises training\n",
    "        #loss_x = (1 + eta) ** 2 / 4 * (x - x_) ** 2\n",
    "\n",
    "        # Check loss_x for NaNs or Infs\n",
    "        #if torch.any(torch.isnan(loss_x)) or torch.any(torch.isinf(loss_x)):\n",
    "        #    print(f\"NaN or Inf detected in loss_x: {loss_x}\")\n",
    "\n",
    "        #loss = 0.5 * loss + 0.5 * loss_x\n",
    "\n",
    "        # Check final loss before applying lambda for NaNs or Infs\n",
    "        if torch.any(torch.isnan(loss)) or torch.any(torch.isinf(loss)):\n",
    "            print(f\"NaN or Inf detected in final loss before lambda: {loss}\")\n",
    "\n",
    "        loss = lmbd * loss \n",
    "\n",
    "        # Check final loss after applying lambda for NaNs or Infs\n",
    "        if torch.any(torch.isnan(loss)) or torch.any(torch.isinf(loss)):\n",
    "            print(f\"NaN or Inf detected in final loss: {loss}\")\n",
    "\n",
    "        # Optionally, you can add assertions here to ensure that no NaN or Inf values propagate.\n",
    "        assert not torch.any(torch.isnan(loss)), f\"NaN detected in final loss: {loss}\"\n",
    "        assert not torch.any(torch.isinf(loss)), f\"Inf detected in final loss: {loss}\"\n",
    "\n",
    "        loss = loss.sum(dim=1)\n",
    "        #print(loss.shape)\n",
    "\n",
    "        # Check final loss sum for NaNs or Infs\n",
    "        if torch.any(torch.isnan(loss)) or torch.any(torch.isinf(loss)):\n",
    "            print(f\"NaN or Inf detected in loss after summing: {loss}\")\n",
    "\n",
    "        \n",
    "        #if we are using VAE we need to also compute the prior VAE loss \n",
    "        if self.VAE:\n",
    "            #print(log_std.shape)\n",
    "            #print(mean.shape)\n",
    "            KLD = -0.5 * torch.sum(1 + (2*log_std) - mean**2 - (2*log_std).exp(), dim=-1)\n",
    "            #print(KLD.shape)\n",
    "            #print(loss.shape)\n",
    "            #print(KLD.requires_grad, \"KLD requires grad\")\n",
    "\n",
    "        #check KLD for NaNs or Infs\n",
    "        if torch.any(torch.isnan(KLD)) or torch.any(torch.isinf(KLD)):\n",
    "            print(f\"NaN or Inf detected in KLD: {KLD}\")\n",
    "            print(KLD)\n",
    "            print(KLD[torch.isinf(KLD)])\n",
    "            print(KLD[torch.isnan(KLD)])\n",
    "            print(KLD[KLD > 10000])\n",
    "        \n",
    "        #print(loss.mean(), \"loss mean\")\n",
    "        return loss, KLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dc20fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2c8916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff5bae11e352252f",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "f391274f4f43b1ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:41:29.261219Z",
     "start_time": "2025-03-09T16:41:29.126692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_sample = gen_data(2 ** 12)\n",
    "\n",
    "viz_2d_data(data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "8d977274d1d3cb88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:41:29.270692Z",
     "start_time": "2025-03-09T16:41:29.267685Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, time_sampler, gen_data_f):\n",
    "    iter = 10 ** 5\n",
    "    bs = 2 ** 10\n",
    "\n",
    "    #set lr higher for model.gamma than for the rest using param group\n",
    "\n",
    "    optim = torch.optim.Adam([*model.parameters(), *time_sampler.parameters()], lr=1e-2)\n",
    "\n",
    "    pbar = trange(iter)\n",
    "    for i in pbar:\n",
    "        x = gen_data_f(bs)\n",
    "\n",
    "        t, p = time_sampler(bs=bs)\n",
    "        t, p = t.detach(), p.detach()\n",
    "\n",
    "        loss, KLD = model(x, t)\n",
    "        loss = loss +  KLD\n",
    "        loss = loss / p + time_sampler.loss(loss.detach(), t)\n",
    "\n",
    "        # plt.scatter(t[:, 0], loss.detach().numpy(), s=1)\n",
    "        # plt.scatter(t[:, 0], p.detach().numpy(), s=1)\n",
    "        # plt.show()\n",
    "\n",
    "        loss = loss.mean()\n",
    "        KLD = KLD.mean()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            pbar.set_description(f\"{loss.item():.4f}, KLD: {KLD.item():.9f}\")\n",
    "\n",
    "        #print(loss)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "a770bbf8afcc9da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:47:36.632794Z",
     "start_time": "2025-03-09T16:41:29.282810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.requires_grad_ of Net(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=64, bias=True)\n",
      "    (1): SELU()\n",
      "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (3): SELU()\n",
      "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (5): SELU()\n",
      "    (6): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (7): SELU()\n",
      "    (8): Linear(in_features=64, out_features=4, bias=True)\n",
      "  )\n",
      ")> model requires grad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1349.8728, KLD: 0.000000339:   7%|▋         | 7167/100000 [01:14<16:02, 96.44it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN or Inf detected in gamma: tensor([[ 3.6927],\n",
      "        [ 4.2067],\n",
      "        [-9.3397],\n",
      "        ...,\n",
      "        [-3.2319],\n",
      "        [ 9.1772],\n",
      "        [ 4.6430]], grad_fn=<ViewBackward0>)\n",
      "tensor([], grad_fn=<IndexBackward0>)\n",
      "tensor([nan, nan], grad_fn=<IndexBackward0>)\n",
      "NaN or Inf detected in d_gamma: tensor([[ 2.3634],\n",
      "        [22.8105],\n",
      "        [85.6236],\n",
      "        ...,\n",
      "        [47.2852],\n",
      "        [ 5.0255],\n",
      "        [11.4119]], grad_fn=<ClampBackward1>)\n",
      "NaN or Inf detected in alpha: tensor([[0.1559],\n",
      "        [0.1211],\n",
      "        [1.0000],\n",
      "        ...,\n",
      "        [0.9808],\n",
      "        [0.0102],\n",
      "        [0.0977]], grad_fn=<PowBackward0>)\n",
      "NaN or Inf detected in sigma: tensor([[0.9878],\n",
      "        [0.9926],\n",
      "        [0.0094],\n",
      "        ...,\n",
      "        [0.1949],\n",
      "        [0.9999],\n",
      "        [0.9952]], grad_fn=<PowBackward0>)\n",
      "NaN or Inf detected in z: tensor([[ 0.7903, -0.1387],\n",
      "        [-1.2840,  1.3712],\n",
      "        [ 0.2465,  2.1813],\n",
      "        ...,\n",
      "        [ 1.4322,  1.9361],\n",
      "        [-2.2517, -0.0403],\n",
      "        [-0.3912, -0.1162]], grad_fn=<AddBackward0>)\n",
      "NaN or Inf detected in x_: tensor([[-0.0242,  1.5020],\n",
      "        [-1.2136,  1.3708],\n",
      "        [ 0.2467,  2.1767],\n",
      "        ...,\n",
      "        [ 1.6482,  2.1279],\n",
      "        [-1.3804,  2.3664],\n",
      "        [-0.6207,  2.1787]], grad_fn=<AddBackward0>)\n",
      "NaN or Inf detected in m_: tensor([[-0.0242,  1.5020],\n",
      "        [-1.2136,  1.3708],\n",
      "        [ 0.2467,  2.1767],\n",
      "        ...,\n",
      "        [ 1.6482,  2.1279],\n",
      "        [-1.3804,  2.3664],\n",
      "        [-0.6207,  2.1787]], grad_fn=<AddBackward0>)\n",
      "NaN or Inf detected in lmbd: tensor([[2.9429e-02],\n",
      "        [1.6988e-01],\n",
      "        [4.8726e+05],\n",
      "        ...,\n",
      "        [5.9880e+02],\n",
      "        [2.5974e-04],\n",
      "        [5.4941e-02]], grad_fn=<DivBackward0>)\n",
      "NaN or Inf detected in loss before squaring: tensor([[ 2.8570, -0.7916],\n",
      "        [-0.5248,  0.1520],\n",
      "        [-0.0087,  0.0102],\n",
      "        ...,\n",
      "        [-0.1250, -0.3520],\n",
      "        [-0.9304, -2.6342],\n",
      "        [-2.4487, -2.1289]], grad_fn=<AddBackward0>)\n",
      "NaN or Inf detected in squared loss: tensor([[8.1623e+00, 6.2666e-01],\n",
      "        [2.7537e-01, 2.3100e-02],\n",
      "        [7.6001e-05, 1.0491e-04],\n",
      "        ...,\n",
      "        [1.5632e-02, 1.2388e-01],\n",
      "        [8.6558e-01, 6.9391e+00],\n",
      "        [5.9962e+00, 4.5323e+00]], grad_fn=<PowBackward0>)\n",
      "NaN or Inf detected in final loss before lambda: tensor([[8.1623e+00, 6.2666e-01],\n",
      "        [2.7537e-01, 2.3100e-02],\n",
      "        [7.6001e-05, 1.0491e-04],\n",
      "        ...,\n",
      "        [1.5632e-02, 1.2388e-01],\n",
      "        [8.6558e-01, 6.9391e+00],\n",
      "        [5.9962e+00, 4.5323e+00]], grad_fn=<PowBackward0>)\n",
      "NaN or Inf detected in final loss: tensor([[2.4021e-01, 1.8442e-02],\n",
      "        [4.6781e-02, 3.9244e-03],\n",
      "        [3.7032e+01, 5.1117e+01],\n",
      "        ...,\n",
      "        [9.3605e+00, 7.4180e+01],\n",
      "        [2.2483e-04, 1.8024e-03],\n",
      "        [3.2943e-01, 2.4901e-01]], grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "NaN detected in final loss: tensor([[2.4021e-01, 1.8442e-02],\n        [4.6781e-02, 3.9244e-03],\n        [3.7032e+01, 5.1117e+01],\n        ...,\n        [9.3605e+00, 7.4180e+01],\n        [2.2483e-04, 1.8024e-03],\n        [3.2943e-01, 2.4901e-01]], grad_fn=<MulBackward0>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[496], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m time_sampler \u001b[38;5;241m=\u001b[39m UniformBucketSampler()\n\u001b[1;32m     29\u001b[0m time_sampler \u001b[38;5;241m=\u001b[39m UniformSampler()\n\u001b[0;32m---> 31\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_sampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_sampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_data_f\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhallo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[495], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, time_sampler, gen_data_f)\u001b[0m\n\u001b[1;32m     13\u001b[0m t, p \u001b[38;5;241m=\u001b[39m time_sampler(bs\u001b[38;5;241m=\u001b[39mbs)\n\u001b[1;32m     14\u001b[0m t, p \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mdetach(), p\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m---> 16\u001b[0m loss, KLD \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m+\u001b[39m  KLD\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m p \u001b[38;5;241m+\u001b[39m time_sampler\u001b[38;5;241m.\u001b[39mloss(loss\u001b[38;5;241m.\u001b[39mdetach(), t)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[493], line 153\u001b[0m, in \u001b[0;36mNeuralDiffusion.forward\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN or Inf detected in final loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# Optionally, you can add assertions here to ensure that no NaN or Inf values propagate.\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(torch\u001b[38;5;241m.\u001b[39misnan(loss)), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN detected in final loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(torch\u001b[38;5;241m.\u001b[39misinf(loss)), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInf detected in final loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: NaN detected in final loss: tensor([[2.4021e-01, 1.8442e-02],\n        [4.6781e-02, 3.9244e-03],\n        [3.7032e+01, 5.1117e+01],\n        ...,\n        [9.3605e+00, 7.4180e+01],\n        [2.2483e-04, 1.8024e-03],\n        [3.2943e-01, 2.4901e-01]], grad_fn=<MulBackward0>)"
     ]
    }
   ],
   "source": [
    "mulan_config = SimpleNamespace(\n",
    "                gamma_shape=(1,),\n",
    "                seq_len= 1,\n",
    "                embedding_dim= 1,#2\n",
    "                gamma_min= -10, #-13.3\n",
    "                gamma_max= 10, # 5\n",
    "                learn_tau=False,\n",
    "                learn_delta=False\n",
    "            )\n",
    "torch.set_grad_enabled(True)           \n",
    "transform = AffineTransformID()\n",
    "#transform = AffineTransformHalfNeural(d=2)\n",
    "\n",
    "#gamma = GammaLinear()\n",
    "#gamma = GammaVDM()\n",
    "#gamma = GammaBad()\n",
    "gamma = GammaMuLAN(mulan_config)\n",
    "\n",
    "\n",
    "vol_eta = VolatilityEtaOne()\n",
    "#vol_eta = VolatilityEtaNeural()\n",
    "\n",
    "pred = Predictor(d=2)\n",
    "\n",
    "ndm = NeuralDiffusion(transform, gamma, vol_eta, pred, VAE=True)#, VAE=True)\n",
    "ndm.train()\n",
    "\n",
    "time_sampler = UniformBucketSampler()\n",
    "time_sampler = UniformSampler()\n",
    "\n",
    "train(model=ndm, time_sampler=time_sampler, gen_data_f=gen_data)\n",
    "print(\"hallo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78b2e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distibution of the VAE latent space\n",
    "def plot_vae_latent_space(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        mean, log_std = model.model(data).chunk(2, dim=1)\n",
    "        std = torch.exp(log_std)\n",
    "        context = mean + std * torch.randn_like(std)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(context[:, 0].numpy(), context[:, 1].numpy(), s=1)\n",
    "    plt.axis(\"scaled\")\n",
    "    plt.title(\"VAE Latent Space\")\n",
    "    plt.show()\n",
    "\n",
    "plot_vae_latent_space(ndm, gen_data(2 ** 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917c48cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pdf(sampler: BucketSampler, num_points=1000):\n",
    "    with torch.no_grad():\n",
    "        # Generate evenly spaced t values\n",
    "        t_values = torch.linspace(0, 1, num_points).view(-1, 1)  # Shape: (num_points, 1)\n",
    "        \n",
    "        # Compute p(t) at these points\n",
    "        p_values = sampler.prob(t_values).cpu().numpy().flatten()\n",
    "        t_values = t_values.cpu().numpy().flatten()\n",
    "\n",
    "        # Compute the integral using the trapezoidal rule\n",
    "        dt = 1 / (num_points - 1)  # Step size\n",
    "        integral = np.trapz(p_values, t_values)  # Numerical integration\n",
    "\n",
    "        # Plot the learned PDF\n",
    "        plt.plot(t_values, p_values, label=f\"Learned PDF (∫p(t)dt ≈ {integral:.4f})\", color=\"b\", linewidth=2)\n",
    "        plt.xlabel(\"t\")\n",
    "        plt.ylabel(\"p(t)\")\n",
    "        plt.title(\"Learned Probability Density Function\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        # Print the integral value\n",
    "        print(f\"Estimated integral of p(t) over [0,1]: {integral:.4f}\")\n",
    "        if abs(integral - 1) > 0.05:\n",
    "            print(\"⚠️ Warning: PDF is not properly normalized!\")\n",
    "        else:\n",
    "            print(\"✅ PDF is properly normalized.\")\n",
    "\n",
    "plot_pdf(time_sampler)\n",
    "\n",
    "#isnt this the wrong way arround? loss should be higher for high t not low t, and gamma isnt focussed on any particular part yet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40946a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    t = torch.linspace(0, 1, 300)[:, None]\n",
    "\n",
    "    gamma_og = GammaMuLAN(mulan_config)\n",
    "    x = gen_data(300)\n",
    "\n",
    "    #g_og, d_gamma = gamma_og(t, x)\n",
    "\n",
    "    g, _ = gamma(t, x)\n",
    "\n",
    "\n",
    "    plt.plot(t, g)\n",
    "    #plt.plot(t, g_og)\n",
    "    plt.legend([\"Learned\", \"Original\"])\n",
    "    plt.show()\n",
    "\n",
    "    #print(d_gamma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81bdea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#also print the loss for these same values of 10\n",
    "#x = gen_data(1).repeat(1000, 1)\n",
    "x = gen_data(1000)\n",
    "t_points = torch.linspace(0, 1, 1000)[:, None]\n",
    "\n",
    "losses = []\n",
    "for t in t_points:\n",
    "    t = t.expand(x.shape[0], 1)\n",
    "    #print(t.shape)\n",
    "    #print(x.shape)\n",
    "    #print(t)\n",
    "    loss = ndm(x, t)\n",
    "    avg_loss = loss.mean()\n",
    "    losses.append(avg_loss.item())\n",
    "\n",
    "\n",
    "print(losses)\n",
    "loss = torch.tensor(losses)\n",
    "plt.plot(t_points, loss.detach().numpy())\n",
    "plt.show() \n",
    "\n",
    "#same "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f1dec6",
   "metadata": {},
   "source": [
    "### Train MuLAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74017b13",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "f^B = \\dot{\\alpha} F + \\alpha \\dot{F} + \\frac{\\dot{\\sigma}}{\\sigma} (z - \\alpha F) - \\frac{g^2}{2} \\frac{\\alpha F - z}{\\sigma^2} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf8700620e4e064",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "\n",
    "### SDE Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb8a518fd897855",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:47:50.212269Z",
     "start_time": "2025-03-09T16:47:45.548537Z"
    }
   },
   "outputs": [],
   "source": [
    "bs = 2 ** 12\n",
    "\n",
    "z = torch.randn(bs, 2)\n",
    "\n",
    "\n",
    "def sde(z_in, t_in):\n",
    "    \n",
    "    x_ = pred(z_in, t_in)\n",
    "    if ndm.VAE:\n",
    "        context = torch.randn_like(z_in)\n",
    "    else:\n",
    "        context = ndm.model(x_)\n",
    "    \n",
    "    gmm, d_gmm = gamma(t_in, context)\n",
    "    alpha_2 = gamma.alpha_2(gmm)\n",
    "    sigma_2 = gamma.sigma_2(gmm)\n",
    "    alpha = alpha_2 ** 0.5\n",
    "    sigma = sigma_2 ** 0.5 #I added this \n",
    "    if torch.any(torch.isnan(gmm)) or torch.any(torch.isinf(gmm)):\n",
    "        print(t_in, \"t_in\")\n",
    "        print(x_, \"x_\")\n",
    "        print(gmm[torch.isnan(gmm)], \"gmm\")\n",
    "        print(\"gmm is nan or inf\")\n",
    "    #print(gmm, \"gmm\")\n",
    "    #print(d_gmm, \"d_gmm\")\n",
    "    #print(alpha_2, \"alpha_2\")\n",
    "    #print(sigma_2, \"sigma_2\")\n",
    "    #print(alpha, \"alpha\")\n",
    "    #print(sigma, \"sigma\")\n",
    "\n",
    "    eta = vol_eta(t_in)\n",
    "\n",
    "    g = (sigma_2 * d_gmm * eta) ** 0.5\n",
    "\n",
    "    (m_, _), (d_m_, _) = transform(x_, t_in)\n",
    "\n",
    "    #print(d_m_, \"d_m\")\n",
    "    #print(sigma_2, \"sigma2\")\n",
    "    #print(eta, \"eta\")\n",
    "    #print(d_gmm, \"d_gmm\")\n",
    "    #print(g, \"g\")\n",
    "\n",
    "    #drift = -alpha * d_gmm * (1 + eta) / 2 * m_ + \\\n",
    "    #        alpha * d_m_ + \\\n",
    "    #        0.5 * d_gmm * (alpha_2 + eta) * z_in\n",
    "    eps = (z_in - alpha * m_) / sigma\n",
    "    alpha_prime = - d_gmm * 0.5 * alpha * (1- alpha_2) \n",
    "    sigma_prime = 0.5 * d_gmm * sigma * (1 - sigma_2)\n",
    "    #dz = -alpha * d_gmm + alpha * d_m_ + sigma * d_gmm * eps\n",
    "    dz = alpha_prime * m_ + alpha * d_m_ + sigma_prime * eps\n",
    "    drift = dz - 0.5 * (g ** 2) * ((alpha * m_ - z_in) / sigma_2)\n",
    "\n",
    "    #print(eps, \"eps\")\n",
    "    #print(alpha_prime, \"alpha_prime\")\n",
    "    #print(sigma_prime, \"sigma_prime\")\n",
    "    #print(dz, \"dz\")\n",
    "    #print(drift, \"drift\")\n",
    "    if torch.any(torch.isnan(drift)) or torch.any(torch.isinf(drift)):\n",
    "        print(\"drift is nan or inf\")\n",
    "    \n",
    "    if torch.any(torch.isnan(g)) or torch.any(torch.isinf(g)):\n",
    "        print(\"g is nan or inf\")\n",
    "\n",
    "    return drift, g\n",
    "\n",
    "\n",
    "_, (t_steps, path) = solve_sde(sde=sde, z=z, ts=1, tf=0, n_steps=300)\n",
    "\n",
    "print(path[-1])\n",
    "viz_2d_path(t_steps, path, n_lines=16, color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c5ebdf",
   "metadata": {},
   "source": [
    "### Star Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e332ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoised_fn(x, t):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7864187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicting_part(prev_sample, t, denoised_fn):\n",
    "    def process_xstart(x):\n",
    "        if denoised_fn is not None:\n",
    "            # print(denoised_fn)\n",
    "            x = denoised_fn(x, t)\n",
    "        if False:# clip_denoised:\n",
    "            return x.clamp(-1, 1)\n",
    "        return x\n",
    "    \n",
    "    out = {}\n",
    "    x_ = pred(prev_sample, t) \n",
    "    \n",
    "    x_start = process_xstart(x_)\n",
    "    out[\"pred_xstart\"] = x_start\n",
    "\n",
    "    gmm, _ = gamma(t)\n",
    "    alpha = gamma.alpha_2(gmm) ** 0.5\n",
    "    sigma2 =  gamma.sigma_2(gmm)\n",
    "\n",
    "    m, _ = transform.get_m_s(x_start, t)\n",
    "\n",
    "    out[\"mean\"] = alpha*m\n",
    "    out[\"log_variance\"] = torch.log(sigma2)\n",
    "\n",
    "\n",
    "    noise = torch.randn_like(prev_sample)\n",
    "    nonzero_mask = (\n",
    "        (t != 0).float().view(-1, *([1] * (len(prev_sample.shape) - 1)))\n",
    "    )  # no noise when t == 0\n",
    "    sample = out[\"mean\"] + nonzero_mask * torch.exp(0.5 * out[\"log_variance\"]) * noise \n",
    "    return sample\n",
    "\n",
    "@torch.no_grad()\n",
    "def discrete_sampling_star(\n",
    "        z: Tensor,\n",
    "        ts: float,\n",
    "        tf: float,\n",
    "        n_steps: int,\n",
    "        show_pbar: bool=True\n",
    "):\n",
    "    bs = z.shape[0]\n",
    "\n",
    "    t_steps = torch.linspace(ts, tf, n_steps + 1)#[:-1]\n",
    "    dt = (tf - ts) / n_steps\n",
    "    dt_2 = abs(dt) ** 0.5\n",
    "\n",
    "    path = [z]\n",
    "    pbar = tqdm if show_pbar else (lambda a: a)\n",
    "    for t in pbar(t_steps):\n",
    "        t = t.expand(bs, 1)\n",
    "\n",
    "        z = predicting_part(prev_sample=z, t=t, denoised_fn=None)\n",
    "\n",
    "        path.append(z)\n",
    "\n",
    "    return z, (t_steps, torch.stack(path[:-1]))\n",
    "\n",
    "\n",
    "bs = 2 ** 12\n",
    "\n",
    "z = torch.randn(bs, 2)\n",
    "\n",
    "_, (t_steps, path) = discrete_sampling_star(z=z, ts=1, tf=0, n_steps=300)\n",
    "\n",
    "print(path[-1])\n",
    "viz_2d_path(t_steps, path, n_lines=16, color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d390c795",
   "metadata": {},
   "source": [
    "### Correct Marginal Sampling\n",
    "\n",
    "\\begin{align}\n",
    "    z_t = F(\\varepsilon, t, x)\n",
    "\\end{align}\n",
    "\n",
    "Then given z_t and t (n(0,1) noise and t=1), do:\n",
    "\n",
    "1. x_0 prediction, $$x\\_ = model.pred(z_t, t)$$\n",
    "2. get epsilon by inverse big F, $$\\varepsilon = \\frac{(z - \\alpha F) }{\\sigma}$$\n",
    "3. get epsilon s|t, \n",
    "\n",
    "\\begin{align}\n",
    "    \\tilde{\\varepsilon}_{s|t} = \\sqrt{1- \\tilde{\\sigma}^2_{s|t}} \\varepsilon + \\tilde{\\sigma}_{s|t} \\tilde{\\varepsilon}\n",
    "\\end{align}\n",
    "\n",
    "where,\n",
    "\n",
    "\\begin{align}\n",
    "    \\tilde{\\sigma}_{s|t} = \\sigma_s^2 - \\frac{SNR(t)}{SNR(s)}\\sigma_s^2\n",
    "\\end{align}\n",
    "\n",
    "and,\n",
    "\n",
    "\\begin{align}\n",
    " \\tilde{\\varepsilon} - N(0,1)? \n",
    "\\end{align}\n",
    "because otherwise no new noise would be injected\n",
    "\n",
    "\n",
    "4. get z_s (next z) by feeding through the forward process. \n",
    "\\begin{align}\n",
    "    z = F(\\tilde{\\varepsilon}_{s|t}, s, x)\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "    z = \\alpha_s F + \\sigma_s (\\sqrt{1- \\tilde{\\sigma}^2_{s|t}} \\varepsilon + \\tilde{\\sigma}_{s|t} \\tilde{\\varepsilon})\n",
    "\\end{align}\n",
    "\n",
    "but that doesnt match the ndm appendix 1 I think? and it doesnt lead to a marginalized standard deviation of sigma_s, which would instead need,\n",
    "\n",
    "\\begin{align}\n",
    "    z = \\alpha_s F + (\\sqrt{\\sigma_s^2 - \\tilde{\\sigma}^2_{s|t}} \\varepsilon + \\tilde{\\sigma}_{s|t} \\tilde{\\varepsilon})\n",
    "\\end{align}\n",
    "\n",
    "which I suppose you could also write as \n",
    "\\begin{align}\n",
    "    \\tilde{\\varepsilon}_{s|t} = \\frac{1}{\\sigma^2_s}(\\sqrt{\\sigma^2_s- \\tilde{\\sigma}^2_{s|t}} \\varepsilon + \\tilde{\\sigma}_{s|t} \\tilde{\\varepsilon})\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8fbe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_marginal(prev_sample, t, s, denoised_fn):\n",
    "    def process_xstart(x):\n",
    "        if denoised_fn is not None:\n",
    "            # print(denoised_fn)\n",
    "            x = denoised_fn(x, t)\n",
    "        if False:# clip_denoised:\n",
    "            return x.clamp(-1, 1)\n",
    "        return x\n",
    "    \n",
    "    #step 1 do prediction \n",
    "    x_ = pred(prev_sample, t) \n",
    "    \n",
    "    x_start = process_xstart(x_)\n",
    "\n",
    "    #step 2 get epsilon\n",
    "    gmm, _ = gamma(t)\n",
    "    alpha2 = gamma.alpha_2(gmm)\n",
    "    sigma2 =  gamma.sigma_2(gmm)\n",
    "    alpha = alpha2 ** 0.5\n",
    "    sigma = sigma2 ** 0.5\n",
    "\n",
    "    m_ , _ = transform.get_m_s(x_start, t)\n",
    "\n",
    "    eps = (prev_sample - alpha * m_) / sigma\n",
    "\n",
    "    #step 3 get epsilon s|t\n",
    "    #we need stepsize for this?\n",
    "    noise = torch.randn_like(prev_sample)\n",
    "    gmm_s, _ = gamma(s)\n",
    "    alpha2_s = gamma.alpha_2(gmm_s)\n",
    "    sigma2_s =  gamma.sigma_2(gmm_s)\n",
    "    alpha_s = alpha2_s ** 0.5\n",
    "    sigma_s = sigma2_s ** 0.5\n",
    "    \n",
    "    m_s , _ = transform.get_m_s(x_start, s)\n",
    "\n",
    "    #print(gmm_s)\n",
    "    snr_t = (alpha2/sigma2).double()\n",
    "    snr_s = (alpha2_s/sigma2_s).double()\n",
    "\n",
    "    #sigma2_tilde_s_t = (1 -  (snr_t / snr_s)).float() #instead of casting back to float here we can alos cast back only after computing epsilon tilde st\n",
    "    sigma2_tilde_s_t = -torch.expm1(gmm_s - gmm) #should be in 0-1\n",
    "    #print(sigma2_tilde_s_t, \"sigma2_tilde_s_t\")\n",
    "\n",
    "    #or option 3\n",
    "\n",
    "    epsilon_tilde_s_t = torch.sqrt(1 - sigma2_tilde_s_t) * eps + (sigma2_tilde_s_t.sqrt()) * noise \n",
    "\n",
    "    #print(\"snr_t\", snr_t[0])\n",
    "    #print(\"snr_s\", snr_s[0])\n",
    "    #print(\"sigma\", sigma2_tilde_s_t) #this should be positive always but isnt so im doing something wrong. \n",
    "\n",
    "    #step 4 get z_s\n",
    "    sample = alpha_s * m_s + sigma_s * epsilon_tilde_s_t\n",
    "    \n",
    "    #if we want to match appendix 1 of ndm paper I think it should instead be\n",
    "    #sample = alpha_s * m_s +  torch.sqrt(sigma2 - sigma2_tilde_s_t) * eps + (sigma2_tilde_s_t ** 0.5) * noise\n",
    "\n",
    "    return sample\n",
    "\n",
    "@torch.no_grad()\n",
    "def discrete_sampling(\n",
    "        z: Tensor,\n",
    "        ts: float,\n",
    "        tf: float,\n",
    "        n_steps: int,\n",
    "        show_pbar: bool=True\n",
    "):\n",
    "    bs = z.shape[0]\n",
    "\n",
    "    t_steps = torch.linspace(ts, tf, n_steps + 1)#[:-1]\n",
    "    dt = (tf - ts) / n_steps\n",
    "    dt_2 = abs(dt) ** 0.5\n",
    "\n",
    "    path = [z]\n",
    "    pbar = tqdm if show_pbar else (lambda a: a)\n",
    "    for t in pbar(t_steps[:-1]):\n",
    "        t = t.expand(bs, 1)\n",
    "\n",
    "        #I understand I am doing 2x-1 the number of needed forward pass through gamma now, Ill fix that before putting it into the actual code.        \n",
    "        z = get_next_marginal(prev_sample=z, t=t, s=t+dt, denoised_fn=None)\n",
    "\n",
    "        path.append(z)\n",
    "\n",
    "    return z, (t_steps, torch.stack(path))\n",
    "\n",
    "\n",
    "bs = 2 ** 12\n",
    "\n",
    "z = torch.randn(bs, 2)\n",
    "\n",
    "_, (t_steps, path) = discrete_sampling(z=z, ts=1, tf=0, n_steps=300)\n",
    "\n",
    "print(path[-1])\n",
    "viz_2d_path(t_steps, path, n_lines=16, color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b811cd",
   "metadata": {},
   "source": [
    "### ODE sampling\n",
    "\n",
    "that means we need just f(z,t,eps)|eps=F(z,t,)înverser. We have, \\\\\n",
    "\\begin{align}\n",
    "    z = F(\\varepsilon, t, x),\n",
    "\\end{align}\n",
    "and specifically in the ndm/vdm case, \\\\\n",
    "\\begin{align}\n",
    "    z = \\alpha F(x, t) + \\sigma \\varepsilon\n",
    "\\end{align}\n",
    "The ODE drift is given by \\\\\n",
    "\\begin{align}\n",
    "    dz = f_{tilde}(z_t, t, x\\_)dt\n",
    "\\end{align}\n",
    "Where \n",
    "\\begin{align}\n",
    "    f_{tilde}(z_t, t, x\\_) &= d/dt F(eps, t, x) \\\\\n",
    "    &= alpha' * m + alpha * dm + sigma' * eps\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "f &= \\dot{\\alpha} F + \\alpha \\dot{F} + \\frac{\\dot{\\sigma}}{\\sigma} (z - \\alpha F) \n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e16e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2 ** 12\n",
    "\n",
    "z = torch.randn(bs, 2)\n",
    "\n",
    "\n",
    "def ode(z_in, t_in):\n",
    "    gmm, d_gmm = gamma(t_in)\n",
    "    alpha_2 = gamma.alpha_2(gmm)\n",
    "    sigma_2 = gamma.sigma_2(gmm)\n",
    "    alpha = alpha_2 ** 0.5\n",
    "    sigma = sigma_2 ** 0.5\n",
    "\n",
    "    #eta = vol_eta(t_in)\n",
    "\n",
    "    x_ = pred(z_in, t_in)\n",
    "\n",
    "    (m_, _), (d_m_, _) = transform(x_, t_in)\n",
    "\n",
    "    eps = (z_in - alpha * m_) / sigma\n",
    "    alpha_prime = - d_gmm * 0.5 * alpha * (1- alpha_2) \n",
    "    sigma_prime = 0.5 * d_gmm * sigma * (1 - sigma_2)\n",
    "    #dz = -alpha * d_gmm + alpha * d_m_ + sigma * d_gmm * eps\n",
    "    dz = alpha_prime * m_ + alpha * d_m_ + sigma_prime * eps\n",
    "    #dz = -alpha_prime + alpha * d_m_ + sigma_prime * eps\n",
    "\n",
    "    \n",
    "    return dz, 0\n",
    "\n",
    "\n",
    "_, (t_steps, path) = solve_sde(sde=ode, z=z, ts=1, tf=0, n_steps=300)\n",
    "\n",
    "viz_2d_path(t_steps, path, n_lines=16, color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05a852b",
   "metadata": {},
   "source": [
    "### Adaptive step size ODE sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314a2d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchdiffeq import odeint\n",
    "\n",
    "def ode_adaptor(t, z):\n",
    "    #print(t)\n",
    "    t = t.expand(z.shape[0], 1)\n",
    "    #print(z.shape)\n",
    "    #print(t.shape) # bs x 2, why is this bs by 2??, needs to be bs x 1 where t moves from 1 to 0 over time\n",
    "    drift, _ = ode(z, t)\n",
    "    return drift\n",
    "\n",
    "@torch.no_grad()\n",
    "def integrate_ode_torch(z0, t_span=(1.0, 0.0), atol=1e-6, rtol=1e-7):\n",
    "    # Here, we only provide the initial conditions (z0) and the time span (t_span)\n",
    "    # The solver will automatically select adaptive time steps within the provided range\n",
    "    t = torch.linspace(1.0, 0.0, 10000)  # Reverse time to go from 1 to 0\n",
    "    # Solve the ODE using RK45 (dopri5 with adaptive step size)\n",
    "    path = odeint(ode_adaptor, z0, t = t, method='dopri5', atol=atol, rtol=rtol)\n",
    "\n",
    "     # The solver automatically handles the time steps\n",
    "    final_state = path[-1]  # Last step of integration\n",
    "\n",
    "    return final_state, (t, path)\n",
    "\n",
    "bs = 2 ** 12\n",
    "print(bs)\n",
    "\n",
    "z = torch.randn(bs, 2)\n",
    "\n",
    "final, (t_steps, path) = integrate_ode_torch(z)\n",
    "\n",
    "print(\"steps taken\", len(path))\n",
    "print(\"steps\", t_steps)\n",
    "\n",
    "viz_2d_data(final.detach().numpy())\n",
    "viz_2d_path(t_steps.detach().numpy(), path.detach().numpy(), n_lines=16, color=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b43e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    t = torch.linspace(0, 1, 300)[:, None]\n",
    "\n",
    "    g, _ = gamma(t)\n",
    "    alpha2 = gamma.alpha_2(g)\n",
    "    sigma2 = gamma.sigma_2(g)\n",
    "    snr = alpha2 / sigma2\n",
    "\n",
    "    plt.plot(t, snr)\n",
    "    plt.show()\n",
    "\n",
    "#clearly t > s implies snr(t) < snr(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf01e04ee671537",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:47:50.335562Z",
     "start_time": "2025-03-09T16:47:50.236564Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    t = torch.linspace(0, 1, 300)[:, None]\n",
    "\n",
    "    g, _ = gamma(t)\n",
    "\n",
    "    plt.plot(g)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9a63e0d4787360",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    t = torch.linspace(0, 1, 300)[:, None]\n",
    "    gmm, dgamma = gamma(t)\n",
    "    alpha_2 = gamma.alpha_2(gmm)\n",
    "    sigma_2 = gamma.sigma_2(gmm)\n",
    "    alpha = alpha_2 ** 0.5\n",
    "    sigma = sigma_2 ** 0.5\n",
    "\n",
    "    #also get alpha and sigma from the sqrt function and plot them in the same graph as the other alpha and sigma, so make three plots\n",
    "\n",
    "    plt.plot(alpha)\n",
    "    plt.legend([\"alpha\", \"alpha_sqrt\"])\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(sigma) #flag2\n",
    "    plt.legend([\"sigma\", \"sigma_sqrt\"])\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(gmm)\n",
    "    plt.legend([\"gamma\"])\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(dgamma)\n",
    "    print(dgamma)\n",
    "    plt.legend([\"dgamma\"])\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
