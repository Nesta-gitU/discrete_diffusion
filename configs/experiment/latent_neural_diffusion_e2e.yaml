# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
    #choose which components to use for the diffusion model
  - /model/components/encoder@model.diffusion.encoder: simple_embedding_encoder.yaml
  - /model/components/decoder@model.diffusion.decoder: lm_head_decoder.yaml
  - /model/components/forward_process@model.diffusion.affine: fm_ot.yaml
  - /model/components/predictor@model.diffusion.pred: predictor.yaml
  - /model/components/volatility@model.diffusion.vol: static_volatility.yaml

  #choose which backbone to use for the predictor and forward process
  - /model/components/transformer@model.diffusion.pred.model: dit.yaml
  
  - override /data: e2e
  - override /model: language_diff_module
  - override /callbacks: default
  - override /trainer: gpu
  
# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["e2e", "dit", "basic_diffusion"]

seed: 12345
#commment
data:
  batch_size: 64
  block_size: 64
  overfit_one_batch: false

callbacks:
  word_sampler:
   log_train_every_n_steps: 25000
   no_epoch_logging: true
  

#one epoch has 12556 batches
#one val epoch has 1396 batches on batch size 256
trainer:
  max_epochs: 300
  check_val_every_n_epoch: 20

model:      
  compute_diffusion_loss: true
  compute_prior_loss: false
  compute_reconstruction_loss: true
  reconstruction_loss_type: collapse
  enable_matmul_tf32: true
  enable_cudnn_tf32: true
  diffusion:
    encoder:
      embedding_dim: 16
    pred:
      model:
        small_input_size: 16 #hopefully this is right. 
        hidden_size: 768

logger:
  wandb:
    tags: ${tags}
    group: "e2e"
    project: "e2e my code" #if just testing garbage use test
    #mode: "disabled" if you dont want ot log a debug run 
  aim:
    experiment: "text8test"
