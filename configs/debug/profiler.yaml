# @package _global_

# runs with execution time profiling

defaults:
  - default

trainer:
  max_epochs: 1
  limit_train_batches: 5
  limit_val_batches: 0
  accelerator: gpu
  #profiler: "simple"
  #profiler: "advanced"
  profiler:
    _target_: pytorch_lightning.profilers.PyTorchProfiler
    with_stack: false                     # Include stack traces
    profile_memory: true                  # Use memory profiler
    on_trace_ready: "${...save_trace}"  # Ensures saving

save_trace:
  _target_: torch.profiler.tensorboard_trace_handler
  dir_name: "./lightning_trace"  # Now it saves the trace here
  

get_memory_profile: true 